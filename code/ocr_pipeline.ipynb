{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8184cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccbdf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def clean_rest_string(input_str):\n",
    "    # Define a regex pattern to remove the hyphen \"—\" and the newline character \"\\n\"\n",
    "    pattern = r'[—\\n\\.]'\n",
    "    # Use the re.sub() function to replace the matched pattern with an empty string\n",
    "    output_str = re.sub(pattern, ' ', input_str)\n",
    "    output_str = re.sub(r'\\s+', ' ', output_str)\n",
    "    return(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953dafe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert to JPG from source\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m convert_from_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/PARIS_1867_Italy.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[1;32m      5\u001b[0m     image\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/Paris1867_Italy_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJPEG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/pdf2image/pdf2image.py:250\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[0;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid, proc \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         data, err \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mcommunicate(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired:\n\u001b[1;32m    252\u001b[0m         proc\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicate(\u001b[38;5;28minput\u001b[39m, endtime, timeout)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/subprocess.py:2075\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2069\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2070\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2072\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2073\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2075\u001b[0m ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert to JPG from source\n",
    "images = convert_from_path('../data/PARIS_1867_Italy.pdf')\n",
    "\n",
    "for count, image in enumerate(images):\n",
    "    image.save(f'../data/Paris1867_Italy_{count}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b85bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path where the image files are located\n",
    "folder_path = '../data'\n",
    "\n",
    "# Initialize an empty dictionary to store the text for each page\n",
    "output_dict = {}\n",
    "\n",
    "# Loop through all the .jpg files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") and \"Paris1867_Italy\" in filename:\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Extract text from the image using pytesseract\n",
    "        text = pytesseract.image_to_string(Image.open(file_path), lang='fra')\n",
    "        \n",
    "        # Add the text to the dictionary with the filename as the key\n",
    "        output_dict[filename] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e1fe5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part of keys and convert to integers\n",
    "numeric_keys = [int(key.split('_')[-1].split('.')[0]) for key in output_dict.keys()]\n",
    "\n",
    "# Pair numeric keys with original keys\n",
    "key_value_pairs = list(zip(output_dict.keys(), output_dict.values()))\n",
    "sorted_pairs = sorted(key_value_pairs, key=lambda x: int(x[0].split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Reconstruct ordered dictionary\n",
    "ordered_dict = {pair[0]: pair[1] for pair in sorted_pairs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6805fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the split text and sources\n",
    "split_text_list = []\n",
    "source_list = []\n",
    "\n",
    "# Iterate through the elements in the output_dict\n",
    "for filename, text in ordered_dict.items():\n",
    "    # Split the text by '\\n\\n' and add the resulting elements to the list\n",
    "    split_entries = text.split('\\n\\n')\n",
    "    \n",
    "    # Add each split entry to the split_text_list and its corresponding source to the source_list\n",
    "    for entry in split_entries:\n",
    "        split_text_list.append(entry)\n",
    "        source_list.append(filename)\n",
    "\n",
    "# Create a pandas DataFrame with 'raw_text' and 'source' columns\n",
    "df = pd.DataFrame({'raw_text': split_text_list, 'source': source_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "141e4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your DataFrame df as described\n",
    "# Create a list to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Initialize a variable to track the 'class' value\n",
    "current_class = None\n",
    "\n",
    "# Iterate through the rows of the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    raw_text = row['raw_text']\n",
    "    source = row['source']\n",
    "    # Check if the row contains the word \"CLASSE\"\n",
    "    if \"CLASSE\" in raw_text:\n",
    "        current_class = raw_text\n",
    "    else:\n",
    "        # If the row does not contain \"CLASSE,\" add it to the list\n",
    "        filtered_data.append({'raw_text': raw_text, 'class': current_class, 'source':source})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "filtered_df = pd.DataFrame(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1554be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>class</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAUME D'ITALIE</td>\n",
       "      <td>120 GROUPE II. — ITALIE. — CLASSE 6.</td>\n",
       "      <td>Paris1867_Italy_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Dalmasso (Henry), imprimerie\\nroyale, à Tur...</td>\n",
       "      <td>CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...</td>\n",
       "      <td>Paris1867_Italy_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. Negro (Auguste-Fréderic), à Tu-\\nrin. — Ouv...</td>\n",
       "      <td>CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...</td>\n",
       "      <td>Paris1867_Italy_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3. Pomba (Louis), à Turin.—Publi-\\ncations de ...</td>\n",
       "      <td>CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...</td>\n",
       "      <td>Paris1867_Italy_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. Gatti (Joseph), à Voghera. —\\nSpécimens de ...</td>\n",
       "      <td>CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...</td>\n",
       "      <td>Paris1867_Italy_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>3. Brameia (Vincent, à Nicotera\\n(Catanzara. —...</td>\n",
       "      <td>CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...</td>\n",
       "      <td>Paris1867_Italy_116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>9. Russo (Dominique), à Nicotera\\n(Catanzaro)....</td>\n",
       "      <td>CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...</td>\n",
       "      <td>Paris1867_Italy_116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>10. Sous-Commission de Oa-\\ntance. — Habilleme...</td>\n",
       "      <td>CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...</td>\n",
       "      <td>Paris1867_Italy_116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>1. Association philanthropique\\nnupolitaine, à...</td>\n",
       "      <td>CLASSE 93. — SPÉCIMENS L'HAWITA-\\nTIONS CARACT...</td>\n",
       "      <td>Paris1867_Italy_116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td></td>\n",
       "      <td>CLASSE 93. — SPÉCIMENS L'HAWITA-\\nTIONS CARACT...</td>\n",
       "      <td>Paris1867_Italy_116.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4446 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_text  \\\n",
       "0                                      ROYAUME D'ITALIE   \n",
       "1     1. Dalmasso (Henry), imprimerie\\nroyale, à Tur...   \n",
       "2     2. Negro (Auguste-Fréderic), à Tu-\\nrin. — Ouv...   \n",
       "3     3. Pomba (Louis), à Turin.—Publi-\\ncations de ...   \n",
       "4     4. Gatti (Joseph), à Voghera. —\\nSpécimens de ...   \n",
       "...                                                 ...   \n",
       "4441  3. Brameia (Vincent, à Nicotera\\n(Catanzara. —...   \n",
       "4442  9. Russo (Dominique), à Nicotera\\n(Catanzaro)....   \n",
       "4443  10. Sous-Commission de Oa-\\ntance. — Habilleme...   \n",
       "4444  1. Association philanthropique\\nnupolitaine, à...   \n",
       "4445                                                      \n",
       "\n",
       "                                                  class  \\\n",
       "0                  120 GROUPE II. — ITALIE. — CLASSE 6.   \n",
       "1     CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...   \n",
       "2     CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...   \n",
       "3     CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...   \n",
       "4     CLASSE 6..— PRUDLITS D'IMPRIMERIE\\nET DE LIBRA...   \n",
       "...                                                 ...   \n",
       "4441  CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...   \n",
       "4442  CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...   \n",
       "4443  CLASSE 92 — SPÉCIMENS DE COs-\\nTUMES POPULAIRE...   \n",
       "4444  CLASSE 93. — SPÉCIMENS L'HAWITA-\\nTIONS CARACT...   \n",
       "4445  CLASSE 93. — SPÉCIMENS L'HAWITA-\\nTIONS CARACT...   \n",
       "\n",
       "                       source  \n",
       "0       Paris1867_Italy_0.jpg  \n",
       "1       Paris1867_Italy_0.jpg  \n",
       "2       Paris1867_Italy_0.jpg  \n",
       "3       Paris1867_Italy_0.jpg  \n",
       "4       Paris1867_Italy_0.jpg  \n",
       "...                       ...  \n",
       "4441  Paris1867_Italy_116.jpg  \n",
       "4442  Paris1867_Italy_116.jpg  \n",
       "4443  Paris1867_Italy_116.jpg  \n",
       "4444  Paris1867_Italy_116.jpg  \n",
       "4445  Paris1867_Italy_116.jpg  \n",
       "\n",
       "[4446 rows x 3 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1758b71",
   "metadata": {},
   "source": [
    "By now, we have OCR'ed all the data. In what follows, we think that some of the line split ups have been done erroneously. Now we correct that on the basis of numbers. Thus, we decrease the number of lines to something closer to the actual number of lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f5cbeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_text = []  # List to store merged text\n",
    "merged_text_source = [] # List to store the class\n",
    "merged_text_class = [] # List to store the source picture\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    starts_with_digit_or_percent = any(char.isdigit() or char == '%' for char in row['raw_text'][:3])\n",
    "    \n",
    "    if not starts_with_digit_or_percent and index > 0:\n",
    "        # Merge the current row's text into the previous row\n",
    "        merged_text[-1] += ' ' + row['raw_text']\n",
    "        merged_text_source[-1] = row['source']\n",
    "        merged_text_class[-1] = row['class']\n",
    "    else:\n",
    "        # Append the current row's text as a new entry\n",
    "        merged_text.append(row['raw_text'])\n",
    "        merged_text_source.append(row['source'])\n",
    "        merged_text_class.append(row['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "67965024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'raw_text':merged_text, 'source':merged_text_source, 'class':merged_text_class})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b861df6",
   "metadata": {},
   "source": [
    "In what follows, we simply rid the text of some annoying symbols without compromising a lot on the structure. Then afterwards, in process_lines, we cut up (increase) the number of lines again, on the basis of numbers, because we felt that some observations were erroneously clustered in 1 line. What results is a very nice and neat vector of raw strings, which should be easy to process. That is the purpose the everything afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2995059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw_text'] = (df['raw_text'].str.replace(r'[^\\w\\s()&]', ' ').\n",
    "                                   str.replace(r'\\s+', ' ').\n",
    "                                   str.replace(r'-', '').\n",
    "                                   str.replace('\\n', '').\n",
    "                                   str.replace('', '').\n",
    "                                   str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cacaa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be ignored in further attempts\n",
    "def process_lines(lines):\n",
    "    for line in lines:\n",
    "        count = 0  # Counter for sequences of consecutive digits\n",
    "        for match in re.finditer(r'\\d+', line):\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                split_index = match.start()  # Get the index of the second sequence of digits\n",
    "                yield line[:split_index]  # Yield the part before the second sequence of digits\n",
    "                yield from process_lines([line[split_index:]])  # Recursively process the remaining part\n",
    "                break\n",
    "        else:\n",
    "            yield line  # If no split occurs, yield the original line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "29d6dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "def process_line(df):\n",
    "    for index, data in df.iterrows():\n",
    "        count = 0  # Counter for sequences of consecutive digits\n",
    "        for match in re.finditer(r'\\d+', data['raw_text']):\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                split_index = match.start()  # Get the index of the second sequence of digits\n",
    "                new_part = pd.Series({\n",
    "                    'raw_text':[data['raw_text'][:split_index]], \n",
    "                    'source':[data['source']],\n",
    "                    'class': [data['class']]})\n",
    "                new_data.append(new_part)  # Append DataFrame with the split part\n",
    "                \n",
    "                # Create a DataFrame for the remaining part\n",
    "                new_line_to_process = pd.DataFrame.from_dict({\n",
    "                    'raw_text': [data['raw_text'][split_index:]],\n",
    "                    'source': [data['source']],\n",
    "                    'class': [data['class']]\n",
    "                })\n",
    "                process_line(new_line_to_process)  # Recursively process the remaining part\n",
    "                next  # Aller a l'itération suivante\n",
    "        # Append the original data when no split occurs\n",
    "            else: \n",
    "                new_data.append(data)\n",
    "\n",
    "# Call the function with your initial DataFrame `df`\n",
    "process_line(df)\n",
    "\n",
    "# Concatenate the list of DataFrames to create a single DataFrame\n",
    "result_df = pd.concat(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "703587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomorrow: See what happens if you remove the lists from some observations\n",
    "## Look at data structure of some obs, should be changed\n",
    "pd.concat(new_data, axis=1).T.reset_index().to_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "651c4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(text):\n",
    "    # Pattern to match word after \"à\" followed by space and potentially words in brackets\n",
    "    pattern_a_accent = r\"(?<=à\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "    \n",
    "    # Pattern to match word after accent aigu without space and potentially words in brackets\n",
    "    pattern_accent_aigu_no_space = r\"(?<=à)(\\w+)(?:\\s*\\((.*?)\\))?|\\Z\"\n",
    "\n",
    "    # Pattern to match word after \"de\" followed by space and potentially words in brackets\n",
    "    pattern_de = r\"(?<=de\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "\n",
    "    # Pattern to match word after \"a\" followed by space and potentially words in brackets\n",
    "    pattern_a = r\"(?<=a\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "\n",
    "    # First, try to match word after \"à\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_a_accent, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    \n",
    "    # If nothing is found, try to match word after accent aigu without space and potentially words in brackets\n",
    "    match = re.search(pattern_accent_aigu_no_space, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "    # If not found, try to match word after \"de\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_de, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "    # If still not found, try to match word after \"a\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_a, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "\n",
    "    # If no matches found, return None\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ce82bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the location:\n",
    "raw_text_df['location'] = raw_text_df['raw_text'].apply(lambda x: extract_location(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final resulting file to .csv\n",
    "# And aftewards continue with name_matching.ipynb\n",
    "raw_text_df.to_csv('../data/1867_italy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
