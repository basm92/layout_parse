{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8184cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbdf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def clean_rest_string(input_str):\n",
    "    # Define a regex pattern to remove the hyphen \"—\" and the newline character \"\\n\"\n",
    "    pattern = r'[—\\n\\.]'\n",
    "    # Use the re.sub() function to replace the matched pattern with an empty string\n",
    "    output_str = re.sub(pattern, ' ', input_str)\n",
    "    output_str = re.sub(r'\\s+', ' ', output_str)\n",
    "    return(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953dafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to JPG from source\n",
    "images = convert_from_path('../data/PARIS_1867_Italy.pdf')\n",
    "\n",
    "for count, image in enumerate(images, start=first_page):\n",
    "    image.save(f'../data/Paris1867_Italy_{count}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b85bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path where the image files are located\n",
    "folder_path = '../data'\n",
    "\n",
    "# Initialize an empty dictionary to store the text for each page\n",
    "output_dict = {}\n",
    "\n",
    "# Loop through all the .jpg files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") and \"Paris1867_Italy\" in filename:\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Extract text from the image using pytesseract\n",
    "        text = pytesseract.image_to_string(Image.open(file_path), lang='fra')\n",
    "        \n",
    "        # Add the text to the dictionary with the filename as the key\n",
    "        output_dict[filename] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6805fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the split text and sources\n",
    "split_text_list = []\n",
    "source_list = []\n",
    "\n",
    "# Iterate through the elements in the output_dict\n",
    "for filename, text in output_dict.items():\n",
    "    # Split the text by '\\n\\n' and add the resulting elements to the list\n",
    "    split_entries = text.split('\\n\\n')\n",
    "    \n",
    "    # Add each split entry to the split_text_list and its corresponding source to the source_list\n",
    "    for entry in split_entries:\n",
    "        split_text_list.append(entry)\n",
    "        source_list.append(filename)\n",
    "\n",
    "# Create a pandas DataFrame with 'raw_text' and 'source' columns\n",
    "df = pd.DataFrame({'raw_text': split_text_list, 'source': source_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90c89a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your DataFrame df as described\n",
    "# Create a list to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Initialize a variable to track the 'class' value\n",
    "current_class = None\n",
    "\n",
    "# Iterate through the rows of the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    raw_text = row['raw_text']\n",
    "    source = row['source']\n",
    "    # Check if the row contains the word \"CLASSE\"\n",
    "    if \"CLASSE\" in raw_text:\n",
    "        current_class = raw_text\n",
    "    else:\n",
    "        # If the row does not contain \"CLASSE,\" add it to the list\n",
    "        filtered_data.append({'raw_text': raw_text, 'class': current_class, 'source':source})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "filtered_df = pd.DataFrame(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1758b71",
   "metadata": {},
   "source": [
    "By now, we have OCR'ed all the data. In what follows, we think that some of the line split ups have been done erroneously. Now we correct that on the basis of numbers. Thus, we decrease the number of lines to something closer to the actual number of lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5cbeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_text = []  # List to store merged text\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not any(char.isdigit() for char in row['raw_text'][:3]) and index > 0:\n",
    "        # Merge the current row's text into the previous row\n",
    "        merged_text[-1] += ' ' + row['raw_text']\n",
    "    else:\n",
    "        # Append the current row's text as a new entry\n",
    "        merged_text.append(row['raw_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b861df6",
   "metadata": {},
   "source": [
    "In what follows, we simply rid the text of some annoying symbols without compromising a lot on the structure. Then afterwards, in process_lines, we cut up (increase) the number of lines again, on the basis of numbers, because we felt that some observations were erroneously clustered in 1 line. What results is a very nice and neat vector of raw strings, which should be easy to process. That is the purpose the everything afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce0e2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = (pd.Series(merged_text).str.replace(r'[^\\w\\s()&]', ' ').\n",
    "                                   str.replace(r'\\s+', ' ').\n",
    "                                   str.replace(r'-', '').\n",
    "                                   str.replace('\\n', '').\n",
    "                                   str.replace('', '').\n",
    "                                   str.strip())\n",
    "#).to_csv('../data/test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cacaa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lines(lines):\n",
    "    for line in lines:\n",
    "        count = 0  # Counter for sequences of consecutive digits\n",
    "        for match in re.finditer(r'\\d+', line):\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                split_index = match.start()  # Get the index of the second sequence of digits\n",
    "                yield line[:split_index]  # Yield the part before the second sequence of digits\n",
    "                yield from process_lines([line[split_index:]])  # Recursively process the remaining part\n",
    "                break\n",
    "        else:\n",
    "            yield line  # If no split occurs, yield the original line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fed27feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lines = list(process_lines(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b78d8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_df = pd.DataFrame(pd.Series(processed_lines), columns=['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "651c4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(text):\n",
    "    # Pattern to match word after \"à\" followed by space and potentially words in brackets\n",
    "    pattern_a_accent = r\"(?<=à\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "    \n",
    "    # Pattern to match word after accent aigu without space and potentially words in brackets\n",
    "    pattern_accent_aigu_no_space = r\"(?<=à)(\\w+)(?:\\s*\\((.*?)\\))?|\\Z\"\n",
    "\n",
    "    # Pattern to match word after \"de\" followed by space and potentially words in brackets\n",
    "    pattern_de = r\"(?<=de\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "\n",
    "    # Pattern to match word after \"a\" followed by space and potentially words in brackets\n",
    "    pattern_a = r\"(?<=a\\s)(\\w+)(?:\\s*\\((.*?)\\))?\"\n",
    "\n",
    "    # First, try to match word after \"à\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_a_accent, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    \n",
    "    # If nothing is found, try to match word after accent aigu without space and potentially words in brackets\n",
    "    match = re.search(pattern_accent_aigu_no_space, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "    # If not found, try to match word after \"de\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_de, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "    # If still not found, try to match word after \"a\" followed by space and potentially words in brackets\n",
    "    match = re.search(pattern_a, text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "\n",
    "\n",
    "    # If no matches found, return None\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ce82bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the location:\n",
    "raw_text_df['location'] = raw_text_df['raw_text'].apply(lambda x: extract_location(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final resulting file to .csv\n",
    "# And aftewards continue with name_matching.ipynb\n",
    "raw_text_df.to_csv('../data/1867_italy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24a11b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_df.to_csv('../data/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
